{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4617cf09-0231-462a-8477-cdacb25ffefd",
   "metadata": {},
   "source": [
    "# Creamos una RAG \"Retrieval-Augmented Generation\" leemos un PDF alimentamos el modelo y lo analizamos con Llama-Index y OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259165a7-1982-46af-99b2-2fe923ab6e42",
   "metadata": {},
   "source": [
    "### Instalamos paquetes y los importamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b496e9de-704f-4a03-ba52-bd5e36b1d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index -q\n",
    "!pip install openai -q\n",
    "!pip install pypdf -q\n",
    "!pip install ipython -q\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e75e82f-c3a6-4910-ac46-44f538f07c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key=\"YourKeyApi\" #Pones la clave de tu API de OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd595b1-47e5-42fd-823e-3bf129587f96",
   "metadata": {},
   "source": [
    "## Creamos una App RAG Basico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9139a2e6-8b1c-4a08-a313-de8188b8a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los documentos contenidos en la carpeta data \"Pdf, xml, txt, etc\"\n",
    "documents = SimpleDirectoryReader(\"./data/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6415ff7b-d839-4374-bce7-1337b04f3dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.schema.Document'>\n",
      "Doc ID: 8ad077f2-6cb1-429e-bad4-a7c31ee8001e\n",
      "Text: Ciencia de datos desde cero Principios básicos con Python 2.ª\n",
      "Edición Joel Grus\n"
     ]
    }
   ],
   "source": [
    "#Confirmamos lectura del documento\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a18059e3-d5a4-46a3-86e5-0d1a46738346",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)  #Creamos los embeddings se usa el modelo ADA-002\n",
    "query_engine = index.as_query_engine() #Creamos el motor y la ventana de contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07178819-4930-482b-a80e-64ea6c58226c",
   "metadata": {},
   "source": [
    "#### Preguntamos al motor y este al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9718634-59a1-4b39-add8-d9afadce279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El libro destaca por su actualización y mejora en comparación con la primera edición. Se ha reescrito todo el código y los ejemplos utilizando Python 3.6, se han añadido nuevos temas como deep learning, estadísticas y procesamiento del lenguaje natural, y se ha hecho énfasis en escribir código limpio. Además, se han reemplazado algunos ejemplos por otros más realistas y se han corregido errores, reescrito explicaciones menos claras y actualizado algunos chistes.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Que es lo que mas destacas del libro\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f016a611-3eae-4ae8-91e9-cb432e9715b2",
   "metadata": {},
   "source": [
    "* Respuesta clara, corta y concreta. Me gusta que confirma la existencia de chistes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb5495-1cfd-440e-8f92-defe4b8bfe5d",
   "metadata": {},
   "source": [
    "### Personalizamos y le damos caracter al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4368f27a-19ba-4101-98f2-26f6320e7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1) #seleccionamos el modelo y le damos un poco de azucar para que sea mas creativo\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5635859d-286d-42e2-b65a-526d0e75da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, embed_model = Settings.embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd19df9c-9d35-4168-b208-df0f813e28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_OpenIA = index.as_query_engine(llm=Settings.llm) # Cambiamos el nombre de la variable Query, para diferenciarlo de la otra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fa8edc7-5f5b-4423-b9f3-8034cfb5b301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La meticulosa revisión y actualización del contenido, incluyendo la reescritura del código y ejemplos en Python 3.6, la incorporación de conjuntos de datos más realistas, la adición de material sobre temas actuales como deep learning, estadísticas y procesamiento del lenguaje natural, así como la corrección de errores y la mejora de las explicaciones, son aspectos destacados del libro.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_OpenIA.query(\n",
    "    \"Que es lo que mas destacas del libro\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358fdc0-ee84-4222-a1dc-6ea37343eaff",
   "metadata": {},
   "source": [
    "### Creamos persistencia del Index en nuestro disco y no en memoria del VectoreStore"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19b919b3-fc48-4602-96cd-6bfd351fc660",
   "metadata": {},
   "source": [
    "Esto evita tener que crear los indices desde cero, cada vez que ejecutemos el modelo, y por el contrario se guardan en disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c968f01-8c04-4e2a-a02f-7a5b6d032dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist() #Creamos la carpeta en la raiz, llamada Storege en el disco local y los guardamos\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\") #Leemos los indices almacenados en el Storage\n",
    "index = load_index_from_storage(storage_context=storage_context) # Cargamos los indices y podremos ejecutar la Query de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02a7e985-b060-49e1-b8a9-1e96519d0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_Local = index.as_query_engine() # Cambiamos el nombre de la variable Query, para diferenciarlo de la otra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a268233e-5f4a-42b2-80aa-815e1b5a0aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the book covers topics related to hacking, specifically focusing on developing computer skills at a hacker level needed for working in data science.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_Local.query(\n",
    "    \"El libro aborda temas de Hacking\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed202570-d007-43f6-9c3a-11ecf1357d48",
   "metadata": {},
   "source": [
    "* Curioso, nos respondio en ingles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5eec022-6211-4b97-98a9-dc3fb87a990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para leer y entender este libro, se deben tener conocimientos en habilidades informáticas a nivel de hacker, matemáticas, estadística y experiencia relevante en ciencia de datos.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine_Local.query(\n",
    "    \"Que conocimientos se deben tener, para leer y entender este libro \"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d33f4-3a41-4c95-aa93-e13704a540fc",
   "metadata": {},
   "source": [
    "* La respuesta me parecio un poco.... fumada, por el termino Hacker. Pero por lo demas es clara y concisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
